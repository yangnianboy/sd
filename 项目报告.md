# 基于扩散模型的多视角视觉错觉图像生成系统

## 项目报告

---

## 一、项目概述

### 1.1 项目背景

视觉错觉（Optical Illusion）是一种利用人类视觉感知特性创造的艺术形式。传统的视觉错觉图像需要艺术家精心设计，耗时且需要专业技能。随着深度学习技术的发展，特别是扩散模型（Diffusion Models）在图像生成领域取得的突破性进展，利用人工智能自动生成视觉错觉图像成为可能。

本项目基于 Visual Anagrams 方法，实现了一个多视角光学错觉图像生成系统。该系统能够生成在不同观察角度下呈现完全不同语义内容的图像，例如：一张图片正向观看是"雪山村庄"，旋转90度后则呈现为"一匹马"。

### 1.2 项目目标

1. 实现基于 DeepFloyd IF 扩散模型的多视角错觉图像生成
2. 支持多种几何变换类型（旋转、翻转、颜色反转等）
3. 提供从64×64到1024×1024的多分辨率图像输出
4. 支持生成展示错觉效果的动画视频
5. 针对显存受限环境进行内存优化

---

## 二、技术原理

### 2.1 扩散模型基础

扩散模型是一类基于马尔可夫链的生成模型，其核心思想包含两个过程：

**前向扩散过程**：逐步向数据添加高斯噪声，直至数据完全变为纯噪声

$$q(x_t|x_{t-1}) = \mathcal{N}(x_t; \sqrt{1-\beta_t}x_{t-1}, \beta_t\mathbf{I})$$

**逆向去噪过程**：学习从噪声中恢复原始数据的过程

$$p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))$$

### 2.2 DeepFloyd IF 模型架构

本项目采用 DeepFloyd IF 模型，这是一个像素级联扩散模型，包含三个阶段：

| 阶段 | 模型 | 输出分辨率 | 功能描述 |
|------|------|------------|----------|
| Stage I | IF-I-L-v1.0 | 64×64 | 基础图像生成 |
| Stage II | IF-II-L-v1.0 | 256×256 | 超分辨率增强 |
| Stage III | SD-x4-Upscaler | 1024×1024 | 最终超分辨率 |

**选择 DeepFloyd IF 而非 Stable Diffusion 的原因**：
- DeepFloyd IF 是像素空间扩散模型，直接在像素级别操作
- Stable Diffusion 是潜在扩散模型（Latent Diffusion），在压缩的潜在空间中操作
- 潜在扩散模型会在视觉错觉中产生伪影，因为 VAE 编解码过程会破坏精细的几何对应关系

### 2.3 多视角去噪算法

Visual Anagrams 的核心创新在于**多视角同时去噪**策略：

```
算法：多视角扩散采样
输入：文本提示集合 {p_1, p_2, ..., p_n}，视角变换集合 {v_1, v_2, ..., v_n}
输出：满足多视角约束的图像 x_0

1. 初始化 x_T ~ N(0, I)
2. for t = T to 1 do:
3.     for i = 1 to n do:
4.         x_t^(i) = v_i(x_t)                    # 应用第i个视角变换
5.         ε_i = ε_θ(x_t^(i), t, p_i)           # 预测第i个视角的噪声
6.         ε_i' = v_i^(-1)(ε_i)                  # 逆变换噪声预测
7.     end for
8.     ε_combined = mean(ε_1', ε_2', ..., ε_n')  # 聚合噪声预测
9.     x_{t-1} = denoise_step(x_t, ε_combined)  # 单步去噪
10. end for
11. return x_0
```

该算法的关键在于：在每个去噪步骤中，对图像应用不同的几何变换，分别用对应的文本提示引导去噪，然后将多个噪声预测进行平均融合。

### 2.4 支持的视角变换

| 变换类型 | 数学表示 | 视觉效果 |
|----------|----------|----------|
| identity | $I$ | 原始视角 |
| rotate_180 | $R_{180°}$ | 旋转180度 |
| rotate_cw | $R_{90°}$ | 顺时针旋转90度 |
| rotate_ccw | $R_{-90°}$ | 逆时针旋转90度 |
| flip | $F_h$ | 水平翻转 |
| negate | $1-x$ | 颜色反转 |
| jigsaw | $P_{jigsaw}$ | 拼图重排 |
| patch_permute | $P_{patch}$ | 块级置换 |

---

## 三、系统设计

### 3.1 系统架构

```
┌─────────────────────────────────────────────────────────────┐
│                        用户接口层                            │
│                      (main.py - CLI)                        │
├─────────────────────────────────────────────────────────────┤
│                        业务逻辑层                            │
│               (generate.py - VisualAnagramGenerator)        │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │ 文本编码模块  │  │ 图像生成模块  │  │ 动画生成模块  │      │
│  │ T5 Encoder   │  │ Stage I/II/III│ │ Animator     │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
├─────────────────────────────────────────────────────────────┤
│                        配置管理层                            │
│                   (config.py / utils.py)                    │
├─────────────────────────────────────────────────────────────┤
│                        模型服务层                            │
│    ┌────────────────────────────────────────────────┐       │
│    │              HuggingFace Diffusers              │       │
│    │  DeepFloyd IF-I-L │ IF-II-L │ SD-x4-Upscaler   │       │
│    └────────────────────────────────────────────────┘       │
├─────────────────────────────────────────────────────────────┤
│                        基础设施层                            │
│           PyTorch │ CUDA │ Transformers │ Accelerate        │
└─────────────────────────────────────────────────────────────┘
```

### 3.2 模块设计

#### 3.2.1 配置模块 (config.py)

集中管理系统配置参数：

| 参数名 | 类型 | 默认值 | 说明 |
|--------|------|--------|------|
| DEVICE | str | 'cuda' | 计算设备 |
| MODEL_STAGE_1 | str | DeepFloyd/IF-I-L-v1.0 | Stage I 模型路径 |
| MODEL_STAGE_2 | str | DeepFloyd/IF-II-L-v1.0 | Stage II 模型路径 |
| MODEL_STAGE_3 | str | stabilityai/stable-diffusion-x4-upscaler | Stage III 模型路径 |
| NUM_INFERENCE_STEPS | int | 30 | 推理步数 |
| GUIDANCE_SCALE | float | 10.0 | 引导强度 |
| NOISE_LEVEL | int | 50 | 噪声等级 |

#### 3.2.2 工具模块 (utils.py)

提供核心工具函数：

- `im_to_np(im)`: 将 PyTorch 张量转换为 NumPy 数组格式
- `flush()`: 执行显存清理，释放 CUDA 缓存

#### 3.2.3 生成器模块 (generate.py)

核心类 `VisualAnagramGenerator` 封装完整的生成流程：

```python
class VisualAnagramGenerator:
    def __init__(self, hf_token)      # 初始化并登录 HuggingFace
    def encode_prompts(self, prompts)  # 编码文本提示
    def load_models(self)              # 加载扩散模型
    def set_views(self, view_types)    # 设置视角变换
    def generate_64(self)              # 生成 64×64 图像
    def generate_256(self, image_64)   # 上采样至 256×256
    def generate_1024(self, image_256) # 上采样至 1024×1024
    def generate(self, prompts, views) # 完整生成流程
    def save_animation(self, image)    # 生成动画
    def get_view_images(self, image)   # 获取各视角图像
```

#### 3.2.4 主程序模块 (main.py)

提供命令行接口：

```bash
python main.py --token <HF_TOKEN> \
               --prompt1 "painting of a mountain" \
               --prompt2 "painting of a cat" \
               --view rotate_cw \
               --output ./result \
               --animate
```

### 3.3 内存优化策略

由于 DeepFloyd IF 模型规模较大（约 40GB 参数），本项目采用以下优化策略：

1. **模型分阶段加载**：T5 编码器与 UNet 不同时驻留显存
2. **FP16 精度推理**：使用半精度浮点数减少显存占用 50%
3. **CPU Offload**：利用 `accelerate` 库实现模型参数的 CPU-GPU 动态迁移
4. **显式内存清理**：在模型切换时调用 `gc.collect()` 和 `torch.cuda.empty_cache()`

```python
# 内存优化示例
text_encoder = T5EncoderModel.from_pretrained(
    "DeepFloyd/IF-I-L-v1.0",
    variant="fp16",              # 使用 FP16 权重
    torch_dtype=torch.float16,   # FP16 计算
    device_map="auto"            # 自动设备映射
)
# 编码完成后立即释放
del text_encoder
gc.collect()
torch.cuda.empty_cache()
```

---

## 四、实验与结果

### 4.1 实验环境

| 配置项 | 规格 |
|--------|------|
| GPU | NVIDIA RTX 5090 32GB |
| CUDA | 11.8+ |
| Python | 3.10+ |
| PyTorch | 2.0+ |
| 显存需求 | 最低 12GB |

### 4.2 生成流程时间分析

| 阶段 | 耗时 | 输出分辨率 |
|------|------|------------|
| T5 文本编码 | ~30s | - |
| Stage I 采样 | ~6s | 64×64 |
| Stage II 采样 | ~27s | 256×256 |
| Stage III 上采样 | ~15s | 1024×1024 |
| 动画生成 | ~60s | 1024×1024 |
| **总计** | **~2.5min** | - |

### 4.3 生成效果示例

**示例 1: 旋转错觉**
- 提示词 1: "painting of a snowy mountain village"
- 提示词 2: "painting of a horse"
- 变换类型: rotate_cw (顺时针旋转90°)
- 效果: 正向观看显示雪山村庄，顺时针旋转90°后显示马的形象

**示例 2: 颜色反转错觉**
- 提示词 1: "Albert Einstein"
- 提示词 2: "Marilyn Monroe"
- 变换类型: negate (颜色反转)
- 效果: 正常观看显示爱因斯坦，颜色反转后显示玛丽莲·梦露

### 4.4 Prompt 设计指南

通过实验总结的有效提示词设计原则：

| 原则 | 说明 | 示例 |
|------|------|------|
| 风格灵活性 | 使用艺术风格描述比写实风格更容易成功 | ✓ "oil painting of" <br> ✗ "photo of" |
| 主体可塑性 | 选择视觉表现灵活的主体 | ✓ "houseplants", "wine and cheese" |
| 面部隐藏 | 人脸作为隐藏主体效果更好 | ✓ "an old man", "Marilyn Monroe" |
| 即时可识别 | 主体需要能被快速识别 | ✓ 著名人物、常见物体 |

---

## 五、项目结构

```
visual-anagrams-project/
│
├── main.py              # 程序入口，CLI 接口
├── generate.py          # 核心生成器类
├── config.py            # 配置参数
├── utils.py             # 工具函数
├── requirements.txt     # Python 依赖
├── README.md            # 项目说明
└── 项目报告.md           # 本报告
```

### 5.1 依赖说明

| 库名 | 版本 | 用途 |
|------|------|------|
| torch | ≥2.0.0 | 深度学习框架 |
| diffusers | ≥0.21.0 | Diffusion 模型管理 |
| transformers | ≥4.30.0 | T5 文本编码器 |
| accelerate | ≥0.21.0 | 模型加速与内存优化 |
| visual_anagrams | latest | 多视角采样核心库 |
| mediapy | ≥1.1.0 | 图像/视频处理 |

---

## 六、总结与展望

### 6.1 项目成果

1. 实现了基于 DeepFloyd IF 的多视角视觉错觉生成系统
2. 支持 12 种不同的几何变换类型
3. 通过内存优化策略，使系统可在消费级 GPU上运行
4. 提供完整的命令行工具和动画生成功能

### 6.2 技术创新点

1. **多视角噪声融合**: 在去噪过程中同时考虑多个视角的约束
2. **级联超分辨率**: 从 64×64 逐步提升至 1024×1024
3. **显存动态管理**: T5 编码器与 UNet 交替加载

---

## 参考文献

1. Geng, D., et al. "Visual Anagrams: Generating Multi-View Optical Illusions with Diffusion Models." CVPR 2024.
2. Ho, J., et al. "Denoising Diffusion Probabilistic Models." NeurIPS 2020.
3. Saharia, C., et al. "Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding." NeurIPS 2022.
4. DeepFloyd Lab. "IF: A Novel State-of-the-Art Open-Source Text-to-Image Model." 2023.

---

**报告完成日期**: 2025年12月


